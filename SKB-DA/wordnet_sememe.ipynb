{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b0df20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, os\n",
    "from nltk.corpus import wordnet as wn\n",
    "from math import log\n",
    "import glob\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "872ccc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getTextFile(langual):\n",
    "    file_list = glob.glob(f'../data/stopwords/stopwords/*_{langual}.txt')\n",
    "    files = \",\".join(file_list)\n",
    "    return files\n",
    "def countMinMaxAver(lines):\n",
    "    min_len = 10000\n",
    "    aver_len = 0\n",
    "    max_len = 0\n",
    "    for temp in lines:\n",
    "        aver_len = aver_len + len(temp)\n",
    "        if len(temp) < min_len:\n",
    "            min_len = len(temp)\n",
    "        if len(temp) > max_len:\n",
    "            max_len = len(temp)\n",
    "    aver_len = 1.0 * aver_len / len(lines)\n",
    "    print('min_len : ' + str(min_len))\n",
    "    print('max_len : ' + str(max_len))\n",
    "    print('average_len : ' + str(aver_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16896da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set()\n",
    "for file in _getTextFile(\"en\").split(\",\"):\n",
    "    for word in open(file):\n",
    "        stop_words.add(word.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ec9e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_json = np.load(\"../data/wordnet_sememe_entity_sence.npy\", allow_pickle=True).tolist()\n",
    "title_content_lemmatization = np.load(\"../data/wordnet_lemmatization_sence.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf94a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49aa5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.add(\"\")\n",
    "stop_words.add(\"'s\")\n",
    "stop_words.add(\"States\")\n",
    "stop_words.add(\"United\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d05f6cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 227733/227733 [00:03<00:00, 75368.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict_l = {}\n",
    "for items in tqdm.tqdm(tagme_json):\n",
    "    if not items:\n",
    "        continue \n",
    "    i, entityList = items.split(\"\\t\")\n",
    "    if entityList == \"null\" or len(entityList) == 0:\n",
    "        continue\n",
    "    entityList = json.loads(entityList)\n",
    "    entities = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    #entities = [d['title'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    title = title_list[int(i)]\n",
    "    if title not in tagme_sememe_dict_l.keys():\n",
    "        tagme_sememe_dict_l[title] = []\n",
    "    entities = \" \".join(entities).strip().split(\" \")\n",
    "    tagme_sememe_dict_l[title] = entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78044d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_sememe_dict = {k:v for k,v in tagme_sememe_dict_l.items() if len(v)!=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a791f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tagme_sememe_dict.items():\n",
    "    def_list = []\n",
    "    for v_i in v:\n",
    "        if v_i not in stop_words:\n",
    "            def_list.append(v_i)\n",
    "    tagme_sememe_dict[k]=def_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da5538f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content lexion:  29629\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}\n",
    "word_set = set()\n",
    "for doc_words in tagme_sememe_dict.values():\n",
    "    for word in doc_words:\n",
    "        word_set.add(word)\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "vocab = list(word_set)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_id_map = {}\n",
    "for i in range(vocab_size):\n",
    "    word_id_map[vocab[i]] = i\n",
    "\n",
    "print(\"content lexion: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18de97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_sorted = sorted(word_freq.items(), key = lambda kv:(kv[1], kv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36ba7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_raw = [word for (word, _) in word_freq_sorted[-5000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed84588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 227733/227733 [00:40<00:00, 5607.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take max [:5000] in content lexion for sememe (raw)\n",
      "min_len : 5\n",
      "max_len : 75\n",
      "average_len : 14.45326050556024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "title_sememe_raw = {}\n",
    "for k, v in tqdm.tqdm(tagme_sememe_dict.items()):\n",
    "    sememe = []\n",
    "    for w in v:\n",
    "        if w in sememe_raw:\n",
    "            sememe.append(w)\n",
    "    if len(sememe) == 0:\n",
    "        continue\n",
    "    title_sememe_raw[k] = sememe\n",
    "\n",
    "print(\"take max [:5000] in content lexion for sememe (raw)\")\n",
    "countMinMaxAver(title_sememe_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "029bf3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sememe lexion size:  5000\n"
     ]
    }
   ],
   "source": [
    "sememe_freq = {}\n",
    "sememe_set = set()\n",
    "for doc_sememes in title_sememe_raw.values():\n",
    "    for sememe in doc_sememes:\n",
    "        sememe_set.add(sememe)\n",
    "        if sememe in sememe_freq:\n",
    "            sememe_freq[sememe] += 1\n",
    "        else:\n",
    "            sememe_freq[sememe] = 1\n",
    "\n",
    "sememe_lexion = list(sememe_set)\n",
    "sememe_lexion_size = len(sememe_lexion)\n",
    "\n",
    "sememe_id_map = {}\n",
    "for i in range(sememe_lexion_size):\n",
    "    sememe_id_map[sememe_lexion[i]] = i\n",
    "\n",
    "print(\"sememe lexion size: \", sememe_lexion_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42d019e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_freq = {}\n",
    "for doc_id,(_, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    for word in doc_words:\n",
    "        word_id = sememe_id_map[word]\n",
    "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
    "        if doc_word_str in doc_word_freq:\n",
    "            doc_word_freq[doc_word_str] += 1\n",
    "        else:\n",
    "            doc_word_freq[doc_word_str] = 1\n",
    "            \n",
    "word_doc_list = {}\n",
    "for i,(_, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    appeared = set()\n",
    "    for word in doc_words:\n",
    "        if word in appeared:\n",
    "            continue\n",
    "        if word in word_doc_list:\n",
    "            doc_list = word_doc_list[word]\n",
    "            doc_list.append(i)\n",
    "            word_doc_list[word] = doc_list\n",
    "        else:\n",
    "            word_doc_list[word] = [i]\n",
    "        appeared.add(word)\n",
    "        \n",
    "word_doc_freq = {}\n",
    "for word, doc_list in word_doc_list.items():\n",
    "    word_doc_freq[word] = len(doc_list)\n",
    "    \n",
    "tfidf_word2doc_all = {}\n",
    "for i,(title, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    doc_word_set = set()\n",
    "    for word in doc_words:\n",
    "        if word in doc_word_set or word == title:\n",
    "            continue\n",
    "        j = sememe_id_map[word]\n",
    "        key = str(i) + ',' + str(j)\n",
    "        freq = doc_word_freq[key]\n",
    "        idf = log(1.0 * len(title_sememe_raw) / word_doc_freq[sememe_lexion[j]])\n",
    "        tfidf_word2doc_all[key] = freq * idf\n",
    "        doc_word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5030e1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 173194\n"
     ]
    }
   ],
   "source": [
    "title_list = [word for word in title_sememe_raw.keys()]\n",
    "tfidf_filter = {}\n",
    "for title, tfidf in tfidf_word2doc_all.items():\n",
    "    if tfidf > 0:\n",
    "        w, d = title.split(\",\")\n",
    "        if title_list[int(w)] not in tfidf_filter.keys():\n",
    "            tfidf_filter[title_list[int(w)]] = []\n",
    "        tfidf_filter[title_list[int(w)]].append(sememe_lexion[int(d)])\n",
    "print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a47b41a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 173194\n"
     ]
    }
   ],
   "source": [
    "# this part for add pmi weight to building graph\n",
    "#title_list = [word for word in title_sememe_raw.keys()]\n",
    "#tfidf_filter = {}\n",
    "#for title, tfidf in tfidf_word2doc_all.items():\n",
    "#    if tfidf > 0:\n",
    "#        w, d = title.split(\",\")\n",
    "#        if title_list[int(w)] not in tfidf_filter.keys():\n",
    "#            tfidf_filter[title_list[int(w)]] = []\n",
    "#        pmi_weight = sememe_lexion[int(d)]+\":\"+str(tfidf)\n",
    "#        tfidf_filter[title_list[int(w)]].append(pmi_weight)\n",
    "#print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00e07908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit:4.549004087244015',\n",
       " 'red:5.246527642403759',\n",
       " 'yellow:4.880575687866226',\n",
       " 'green:5.59913817555742',\n",
       " 'skin:5.256445079061105',\n",
       " 'sweet:6.0782313517909',\n",
       " 'tart:8.398605986348445',\n",
       " 'flesh:6.705581357806078']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf_filter[\"apple.n.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10f6e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 173194\n"
     ]
    }
   ],
   "source": [
    "#print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fd33cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"wordnet_sememe_163340\", tfidf_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dccdea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sememe_network_pmi = {}\n",
    "#for k,v in tfidf_filter.items():\n",
    "#    for vi in v:\n",
    "#        vi,pmi=vi.split(\":\")\n",
    "#        if vi in sememe_network[k]:\n",
    "#            if k not in sememe_network_pmi.keys():\n",
    "#                sememe_network_pmi[k] = []\n",
    "#            sememe_network_pmi[k].append(vi+\":\"+pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "744acb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(sememe_network_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8587499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"wordnet_sememe_163340_218\", sememe_network_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af3f6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96290d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_id_map = {w:i for i,w in enumerate(title_list)}\n",
    "#max_value = 4\n",
    "#sememe_network = {}\n",
    "#for word, sememes in tfidf_filter.items():\n",
    "#    if len(sememes) != 0:\n",
    "#        if len(sememes) > max_value:\n",
    "#            sememe_freq_max_value = {}\n",
    "#            for sememe in sememes:\n",
    "#                tfidf_word2doc_all_key = str(title_id_map[word]) +\",\"+ str(sememe_id_map[sememe])\n",
    "#                sememe_freq_max_value[sememe] = tfidf_word2doc_all[tfidf_word2doc_all_key]\n",
    "#            sememe_lower = sorted(sememe_freq_max_value.items(),key=lambda item:item[1],reverse=True)[:max_value]\n",
    "#            sememe_lower = [sememe_set[0] for sememe_set in sememe_lower]\n",
    "#            sememe_network[word] = sememe_lower\n",
    "#        else:\n",
    "#            sememe_network[word] = sememes\n",
    "#    else:\n",
    "#        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d16cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d0c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 227733/227733 [00:03<00:00, 73691.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict = {}\n",
    "for items in tqdm.tqdm(tagme_json):\n",
    "    if not items:\n",
    "        continue \n",
    "    i, entityList = items.split(\"\\t\")\n",
    "    if entityList == \"null\" or len(entityList) == 0:\n",
    "        continue\n",
    "    entityList = json.loads(entityList)\n",
    "    #entities = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    entities = [d['title']+\"#\"+str(d['link_probability']) for d in entityList if 'title' in d and float(d['rho']) > 0.01]\n",
    "    #print(i)\n",
    "    title = title_list[int(i)]\n",
    "    if title not in tagme_sememe_dict.keys():\n",
    "        tagme_sememe_dict[title] = []\n",
    "    tagme_sememe_dict[title] = entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67cef498",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization.keys())\n",
    "max_value = 10\n",
    "sememe_network = {}\n",
    "for word, sememes in tfidf_filter.items():\n",
    "    if len(sememes) != 0:\n",
    "        if len(sememes) > max_value:\n",
    "            tagme_sememe_dict_v = tagme_sememe_dict[word]\n",
    "            sememe_freq_max_value = {}\n",
    "            for sememe in sememes:\n",
    "                for v in tagme_sememe_dict_v:\n",
    "                    #print(v)\n",
    "                    s, l = v.split(\"#\")\n",
    "                    if s == sememe:\n",
    "                        sememe_freq_max_value[sememe] = float(l)\n",
    "            sememe_lower = sorted(sememe_freq_max_value.items(),key=lambda item:item[1],reverse=True)[:max_value]\n",
    "            sememe_lower = [sememe_set[0] for sememe_set in sememe_lower]\n",
    "            sememe_network[word] = sememe_lower\n",
    "        else:\n",
    "            sememe_network[word] = sememes\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e426e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 4\n",
    "sememe_network = {}\n",
    "for word, sememes in tfidf_filter.items():\n",
    "    if len(sememes) != 0:\n",
    "        if len(sememes) > max_value:\n",
    "            sememe_freq_max_value = {}\n",
    "            for sememe in sememes:\n",
    "                sememe_freq_max_value[sememe] = sememe_freq[sememe]\n",
    "            sememe_lower = sorted(sememe_freq_max_value.items(),key=lambda item:item[1],reverse=True)[:max_value]\n",
    "            sememe_lower = [sememe_set[0] for sememe_set in sememe_lower]\n",
    "            sememe_network[word] = sememe_lower\n",
    "        else:\n",
    "            sememe_network[word] = sememes\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73931abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_network = {k:v for k,v in sememe_network.items() if len(v)!=0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "785cb697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 171580\n"
     ]
    }
   ],
   "source": [
    "print(\"all lexion size:\", len(sememe_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "141b21bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3766464622916423"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(v) for v in sememe_network.values()])/len(sememe_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "949399f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5069979329537975"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(v) for v in tfidf_filter.values()])/len(tfidf_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f982e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  5000\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}\n",
    "word_set = set()\n",
    "for words in sememe_network.values():\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "vocab = list(word_set)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_id_map = {}\n",
    "for i in range(vocab_size):\n",
    "    word_id_map[vocab[i]] = i\n",
    "\n",
    "print(\"vocab_size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c68dbf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit', 'red', 'yellow', 'green', 'skin', 'sweet', 'tart', 'flesh']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sememe_network[\"apple.n.0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eb1c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_network = {k:set(v) for k, v in sememe_network.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92d85f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_network_dict = {}\n",
    "for k, v in sememe_network.items():\n",
    "    word = k.split(\".\")[:-2]\n",
    "    pos = k.split(\".\")[-2]\n",
    "    index = k.split(\".\")[-1]\n",
    "    if \"\".join(word) not in sememe_network_dict.keys():\n",
    "        sememe_network_dict[\"\".join(word)] = []\n",
    "    sememe_network_dict[\"\".join(word)].append((pos,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae30f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', {'flesh', 'fruit', 'green', 'red', 'skin', 'sweet', 'tart', 'yellow'}),\n",
       " ('n',\n",
       "  {'Eurasian', 'cultivate', 'edible', 'fruit', 'native', 'tree', 'variety'})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sememe_network_dict[\"apple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36aa4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sememe_network_dict_en_wordnet_5000\",sememe_network)\n",
    "np.save(\"sememe_network_cdv_en_wordnet_5000\",vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a17bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca00368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
