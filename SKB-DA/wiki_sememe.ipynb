{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d7a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, os\n",
    "from nltk.corpus import wordnet as wn\n",
    "from math import log\n",
    "import glob\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264bfcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getTextFile(langual):\n",
    "    file_list = glob.glob(f'../data/stopwords/stopwords/*_{langual}.txt')\n",
    "    files = \",\".join(file_list)\n",
    "    return files\n",
    "def countMinMaxAver(lines):\n",
    "    min_len = 10000\n",
    "    aver_len = 0\n",
    "    max_len = 0\n",
    "    for temp in lines:\n",
    "        aver_len = aver_len + len(temp)\n",
    "        if len(temp) < min_len:\n",
    "            min_len = len(temp)\n",
    "        if len(temp) > max_len:\n",
    "            max_len = len(temp)\n",
    "    aver_len = 1.0 * aver_len / len(lines)\n",
    "    print('min_len : ' + str(min_len))\n",
    "    print('max_len : ' + str(max_len))\n",
    "    print('average_len : ' + str(aver_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb805a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set()\n",
    "for file in _getTextFile(\"en\").split(\",\"):\n",
    "    for word in open(file):\n",
    "        stop_words.add(word.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beac6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_entity_sence = np.load(\"../data/sememe_entity_sence.npy\", allow_pickle=True).tolist()\n",
    "title_content_lemmatization_sence = np.load(\"../data/title_content_lemmatization_sence.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d50603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization_sence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ff4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.add(\"\")\n",
    "stop_words.add(\"'s\")\n",
    "stop_words.add(\"States\")\n",
    "stop_words.add(\"United\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "641fc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdv = np.load(\"./sememe_network_cdv_en_wordnet_5000.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad73ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 960853/960853 [00:23<00:00, 41272.59it/s]\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict_l = {}\n",
    "for items in tqdm.tqdm(sememe_entity_sence):\n",
    "    if not items:\n",
    "        continue \n",
    "    i, entityList = items.split(\"\\t\")\n",
    "    if entityList == \"null\" or len(entityList) == 0:\n",
    "        continue\n",
    "    entityList = json.loads(entityList)\n",
    "    entities = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    #entities = [d['title'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    title = title_list[int(i)]\n",
    "    if title not in tagme_sememe_dict_l.keys():\n",
    "        tagme_sememe_dict_l[title] = []\n",
    "    entities = \" \".join(entities).strip().split(\" \")\n",
    "    tagme_sememe_dict_l[title] = entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5cca597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 960676/960676 [05:56<00:00, 2697.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take max [:5000] in content lexion for sememe (raw)\n",
      "min_len : 6\n",
      "max_len : 216\n",
      "average_len : 16.220363262073196\n"
     ]
    }
   ],
   "source": [
    "title_sememe_raw = {}\n",
    "for k, v in tqdm.tqdm(tagme_sememe_dict_l.items()):\n",
    "    sememe = []\n",
    "    for w in v:\n",
    "        if w in cdv:\n",
    "        #if w in dict_sememes:\n",
    "            sememe.append(w)\n",
    "    if len(sememe) == 0:\n",
    "        continue\n",
    "    title_sememe_raw[k] = sememe\n",
    "\n",
    "print(\"take max [:5000] in content lexion for sememe (raw)\")\n",
    "countMinMaxAver(title_sememe_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50dd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sememe lexion size:  4442\n"
     ]
    }
   ],
   "source": [
    "sememe_freq = {}\n",
    "sememe_set = set()\n",
    "for doc_sememes in title_sememe_raw.values():\n",
    "    for sememe in doc_sememes:\n",
    "        sememe_set.add(sememe)\n",
    "        if sememe in sememe_freq:\n",
    "            sememe_freq[sememe] += 1\n",
    "        else:\n",
    "            sememe_freq[sememe] = 1\n",
    "\n",
    "sememe_lexion = list(sememe_set)\n",
    "sememe_lexion_size = len(sememe_lexion)\n",
    "\n",
    "sememe_id_map = {}\n",
    "for i in range(sememe_lexion_size):\n",
    "    sememe_id_map[sememe_lexion[i]] = i\n",
    "\n",
    "print(\"sememe lexion size: \", sememe_lexion_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c660b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_freq = {}\n",
    "for doc_id,(_, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    for word in doc_words:\n",
    "        word_id = sememe_id_map[word]\n",
    "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
    "        if doc_word_str in doc_word_freq:\n",
    "            doc_word_freq[doc_word_str] += 1\n",
    "        else:\n",
    "            doc_word_freq[doc_word_str] = 1\n",
    "            \n",
    "word_doc_list = {}\n",
    "for i,(_, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    appeared = set()\n",
    "    for word in doc_words:\n",
    "        if word in appeared:\n",
    "            continue\n",
    "        if word in word_doc_list:\n",
    "            doc_list = word_doc_list[word]\n",
    "            doc_list.append(i)\n",
    "            word_doc_list[word] = doc_list\n",
    "        else:\n",
    "            word_doc_list[word] = [i]\n",
    "        appeared.add(word)\n",
    "        \n",
    "word_doc_freq = {}\n",
    "for word, doc_list in word_doc_list.items():\n",
    "    word_doc_freq[word] = len(doc_list)\n",
    "    \n",
    "tfidf_word2doc_all = {}\n",
    "for i,(title, doc_words) in enumerate(title_sememe_raw.items()):\n",
    "    doc_word_set = set()\n",
    "    for word in doc_words:\n",
    "        if word in doc_word_set or word == title:\n",
    "            continue\n",
    "        j = sememe_id_map[word]\n",
    "        key = str(i) + ',' + str(j)\n",
    "        freq = doc_word_freq[key]\n",
    "        idf = log(1.0 * len(title_sememe_raw) / word_doc_freq[sememe_lexion[j]])\n",
    "        tfidf_word2doc_all[key] = freq * idf\n",
    "        doc_word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9530b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 649708\n"
     ]
    }
   ],
   "source": [
    "title_list = [word for word in title_sememe_raw.keys()]\n",
    "tfidf_filter = {}\n",
    "for title, tfidf in tfidf_word2doc_all.items():\n",
    "    if tfidf > 4:\n",
    "        w, d = title.split(\",\")\n",
    "        if title_list[int(w)] not in tfidf_filter.keys():\n",
    "            tfidf_filter[title_list[int(w)]] = []\n",
    "        tfidf_filter[title_list[int(w)]].append(sememe_lexion[int(d)])\n",
    "print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b5007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part for add pmi weight to building graph\n",
    "#title_list = [word for word in title_sememe_raw.keys()]\n",
    "#tfidf_filter = {}\n",
    "#for title, tfidf in tfidf_word2doc_all.items():\n",
    "#    if tfidf > 4:\n",
    "#        w, d = title.split(\",\")\n",
    "#        if title_list[int(w)] not in tfidf_filter.keys():\n",
    "#            tfidf_filter[title_list[int(w)]] = []\n",
    "#        pmi_weight = sememe_lexion[int(d)]+\":\"+str(tfidf)\n",
    "#        tfidf_filter[title_list[int(w)]].append(pmi_weight)\n",
    "#print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3dafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_filter = {k:v for k, v in tfidf_filter.items() if k in sememe_network.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0b8df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"all lexion size:\", len(tfidf_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "867d8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"wiki_sememe_423249_212\", tfidf_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7372f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization_sence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e8b9581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 960853/960853 [00:27<00:00, 34524.26it/s]\n"
     ]
    }
   ],
   "source": [
    "tagme_sememe_dict = {}\n",
    "for items in tqdm.tqdm(sememe_entity_sence):\n",
    "    if not items:\n",
    "        continue \n",
    "    i, entityList = items.split(\"\\t\")\n",
    "    if entityList == \"null\" or len(entityList) == 0:\n",
    "        continue\n",
    "    entityList = json.loads(entityList)\n",
    "    #entities = [d['spot'] for d in entityList if 'title' in d and float(d['rho']) > 0.1]\n",
    "    entities = [d['title']+\"#\"+str(d['link_probability']) for d in entityList if 'title' in d and float(d['rho']) > 0.01]\n",
    "    #print(i)\n",
    "    title = title_list[int(i)]\n",
    "    if title not in tagme_sememe_dict.keys():\n",
    "        tagme_sememe_dict[title] = []\n",
    "    tagme_sememe_dict[title] = entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d258fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(title_content_lemmatization_sence.keys())\n",
    "max_value = 10\n",
    "sememe_network = {}\n",
    "for word, sememes in tfidf_filter.items():\n",
    "    if len(sememes) != 0:\n",
    "        if len(sememes) > max_value:\n",
    "            tagme_sememe_dict_v = tagme_sememe_dict[word]\n",
    "            sememe_freq_max_value = {}\n",
    "            for sememe in sememes:\n",
    "                for v in tagme_sememe_dict_v:\n",
    "                    #print(v)\n",
    "                    s, l = v.split(\"#\")\n",
    "                    if s == sememe:\n",
    "                        sememe_freq_max_value[sememe] = float(l)\n",
    "            sememe_lower = sorted(sememe_freq_max_value.items(),key=lambda item:item[1],reverse=True)[:max_value]\n",
    "            sememe_lower = [sememe_set[0] for sememe_set in sememe_lower]\n",
    "            sememe_network[word] = sememe_lower\n",
    "        else:\n",
    "            sememe_network[word] = sememes\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69c65404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all lexion size: 649708\n"
     ]
    }
   ],
   "source": [
    "print(\"all lexion size:\", len(sememe_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c860a56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.373934136565965"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(v) for v in sememe_network.values()])/len(sememe_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki 423249 2.1226677440466486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0588e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  4436\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}\n",
    "word_set = set()\n",
    "for words in sememe_network.values():\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "vocab = list(word_set)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_id_map = {}\n",
    "for i in range(vocab_size):\n",
    "    word_id_map[vocab[i]] = i\n",
    "\n",
    "print(\"vocab_size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02a38661",
   "metadata": {},
   "outputs": [],
   "source": [
    "sememe_network = {k:v for k, v in sememe_network.items() if len(v) != 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353b487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sememe_network.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7837a64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflammation',\n",
       " 'colon',\n",
       " 'acute',\n",
       " 'long',\n",
       " 'term',\n",
       " 'fit',\n",
       " 'digestive',\n",
       " 'disease']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sememe_network['colitis>>>NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbe5faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"sememe_network_dict_en_wiki_5000\",sememe_network)\n",
    "np.save(\"sememe_network_cdv_en_wiki_5000\",vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8349e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
